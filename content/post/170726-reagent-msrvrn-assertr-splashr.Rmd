---
title: "Scraping javascript generated content with splashr"
author: "Xavier Adam"
date: "2017-07-26"
categories: ["R"]
tags: ["R","RMarkdown","rvest","xml2","purrr","dplyr","scraping","splashr","harbor","javascript"]
---
## Introduction

While scraping rental listings, it's useful to verify that the scripts managed to grab all the offers. This is nice to have on simple [fully loaded single page](https://www.moservernet.ch/en/apartments-for-rent/), but even nicer if the rental listings are set up as a [infinite scroll page](http://www.brolliet.ch/en/rent/), which seem increasingly popular on real estate websites and require multiple calls from the scraper.

![Count of offers on rental websites.](/img/1707263-scrsh-count-msrvrn.png)

Even when they don't load all the results, the websites nearly always indicate the number of matched offers. This can be used to verify that our final dataset has the correct number of rows.

## Scraping the data
### Scraping static content

Using [our previous example](https://xvrdm.github.io/2017/03/31/scrape-a-list-of-rental-offers-using-rvest-and-purrr/), we can see that the number of matched offers is written on the page.

![Count of offers can be found on the page.](/img/1707261-scrsh-count-msrvrn.png)

Inspect the html of the page to find the id/class of the number of results and store it in a variable. We can complete the code as below:

```{r}
# Load needed packages
suppressMessages(library(xml2))
suppressMessages(library(rvest))

# Create an html document
listing_url <- "https://www.moservernet.ch/en/apartments-for-rent/"
listing_html <- xml2::read_html(listing_url)

# Find the number of listed offers
listing_html %>%
  html_node("#count-search") %>%
  html_text()
```

Empty? It looks like the count is actually populated by a tiny bit of javascript, so it's not available when we parse the page source.

![The counter is updated by Javascript.](/img/1707262-scrsh-js-msrvrn.png)


### Scraping content generated by javascript

`xml2::read_html` by itself cannot inspect the content generated by javascript. For that we can use another library [`splashr`](https://github.com/hrbrmstr/splashr). In a nutshell, `splashr` lets you spin and interact with a [splash](https://splash.readthedocs.io/en/stable/) headless browser in a [docker](https://www.docker.com/) container. If this sounds like jibberish, let's try a translation:

- "spin and interact with a headless browser": create a virtual browser (we won't see it, it happens in the background) that will browse/render the page and give us back it's content (including the javascript generated content). "Splash" is one these headless browsers, but you might have heard of another one named "phantomJS".
- "in a docker container": think of docker is a way to easily run lightweight virtual machines (called container). So rather than installing splash and all its python dependencies, we will run a virtual machine with splash installed in it and destroy it when we are done, leaving our main system untouched.

Installing docker is beyond the scope of this post, but there are tons of ressource online. At the time of this writing, to install [`splashr`](https://github.com/hrbrmstr/splashr) and [`docker`](https://github.com/bhaskarvk/docker) (the package that manages docker from R), you need to grab them from github.

The github page of [`docker`](https://github.com/bhaskarvk/docker) (the R package) explains how to install the python package [`docker`](https://docker-py.readthedocs.io/en/stable/). Yes, you read that well: in order to use [`splash`](http://splash.readthedocs.io) (the scrapping python lib),  [`splashr`](https://github.com/hrbrmstr/[splashr) uses:

- [`docker`](https://github.com/bhaskarvk/docker) (the R package), 
    - which uses [`docker`](https://docker-py.readthedocs.io/en/stable/) (the python lib installed in a virtualenv named `docker`), 
        - which uses [`docker`](https://www.docker.com/) (the container engine).

So proceed in steps:

1. Install [`docker`](https://www.docker.com/) (the engine)
2. Install [`docker`](https://docker-py.readthedocs.io/en/stable/) (the python lib) in a virtualenv like explained [here](https://github.com/bhaskarvk/docker)
3. Install the R packages

```
devtools::install_github("bhaskarvk/docker")
devtools::install_github("hrbrmstr/splashr")
```

4. Let RStudio know that you want python commands to be run in this virtualenv

```{r}
# Use the path where you installed the docker venv
reticulate::use_virtualenv("~/dev/virtualenvs/docker", required=T)
```

The very first time we run `splashr`, it might be a bit slow: it will have to download the docker image (the template used to create container) that has `Splash` installed in it. The image is documented [here](https://hub.docker.com/r/hrbrmstr/splashttpd/).

```{r}
suppressMessages(library(splashr))
install_splash()
```

We can then use `splashr` to create a `splash` container and get the `html`, this time with javascript generated content in it. The `xml2` functions can still be used on the html returned by `splashr`. 

I added a wait time of two seconds between `start_splash` and `render_html` because I kept getting errors looking like `render_html` was called before the container was fully operational.

```{r}
splash_container <- splashr::start_splash()
Sys.sleep(2)
listing_html_js <- splashr::render_html(url = listing_url)

count <- listing_html_js %>%
  html_node("#count-search") %>%
  html_text()
print(paste("count value is:", count))
```

The number is extracted with a little regular expression and the `stringr` package:

```{r}
offer_number <- stringr::str_extract(count, "[0-9]+") 
print(paste("offer_number value is:", offer_number))
```

Don't forget to stop and delete your container.

```{r}
stop_splash(splash_container)
```

We now have the expected number of offers, which we can use to verify our final dataset (read [previous post](https://xvrdm.github.io/2017/03/31/scrape-a-list-of-rental-offers-using-rvest-and-purrr/) to see how).