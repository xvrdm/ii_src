---
title: "Scraping javascript generated content with splashr"
author: "Xavier Adam"
date: "2017-07-26"
categories: ["R"]
tags: ["R","RMarkdown","rvest","xml2","purrr","dplyr","scraping","splashr","harbor","javascript"]
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>While scraping rental listings, it’s useful to verify that the scripts managed to grab all the offers. This is nice to have on simple <a href="https://www.moservernet.ch/en/apartments-for-rent/">fully loaded single page</a>, but even nicer if the rental listings are set up as a <a href="http://www.brolliet.ch/en/rent/">infinite scroll page</a>, which seem increasingly popular on real estate websites and require multiple calls from the scraper.</p>
<div class="figure">
<img src="/img/1707263-scrsh-count-msrvrn.png" alt="Count of offers on rental websites." />
<p class="caption">Count of offers on rental websites.</p>
</div>
<p>Even when they don’t load all the results, the websites nearly always indicate the number of matched offers. This can be used to verify that our final dataset has the correct number of rows.</p>
</div>
<div id="scraping-the-data" class="section level2">
<h2>Scraping the data</h2>
<div id="scraping-static-content" class="section level3">
<h3>Scraping static content</h3>
<p>Using <a href="https://xvrdm.github.io/2017/03/31/scrape-a-list-of-rental-offers-using-rvest-and-purrr/">our previous example</a>, we can see that the number of matched offers is written on the page.</p>
<div class="figure">
<img src="/img/1707261-scrsh-count-msrvrn.png" alt="Count of offers can be found on the page." />
<p class="caption">Count of offers can be found on the page.</p>
</div>
<p>Inspect the html of the page to find the id/class of the number of results and store it in a variable. We can complete the code as below:</p>
<pre class="r"><code># Load needed packages
suppressMessages(library(xml2))
suppressMessages(library(rvest))

# Create an html document
listing_url &lt;- &quot;https://www.moservernet.ch/en/apartments-for-rent/&quot;
listing_html &lt;- xml2::read_html(listing_url)

# Find the number of listed offers
listing_html %&gt;%
  html_node(&quot;#count-search&quot;) %&gt;%
  html_text()</code></pre>
<pre><code>## [1] &quot;()&quot;</code></pre>
<p>Empty? It looks like the count is actually populated by a tiny bit of javascript, so it’s not available when we parse the page source.</p>
<div class="figure">
<img src="/img/1707262-scrsh-js-msrvrn.png" alt="The counter is updated by Javascript." />
<p class="caption">The counter is updated by Javascript.</p>
</div>
</div>
<div id="scraping-content-generated-by-javascript" class="section level3">
<h3>Scraping content generated by javascript</h3>
<p><code>xml2::read_html</code> by itself cannot inspect the content generated by javascript. For that we can use another library <a href="https://github.com/hrbrmstr/splashr"><code>splashr</code></a>. In a nutshell, <code>splashr</code> lets you spin and interact with a <a href="https://splash.readthedocs.io/en/stable/">splash</a> headless browser in a <a href="https://www.docker.com/">docker</a> container. If this sounds like jibberish, let’s try a translation:</p>
<ul>
<li>“spin and interact with a headless browser”: create a virtual browser (we won’t see it, it happens in the background) that will browse/render the page and give us back it’s content (including the javascript generated content). “Splash” is one these headless browsers, but you might have heard of another one named “phantomJS”.</li>
<li>“in a docker container”: think of docker is a way to easily run lightweight virtual machines (called container). So rather than installing splash and all its python dependencies, we will run a virtual machine with splash installed in it and destroy it when we are done, leaving our main system untouched.</li>
</ul>
<p>Installing docker is beyond the scope of this post, but there are tons of ressource online. At the time of this writing, to install <a href="https://github.com/hrbrmstr/splashr"><code>splashr</code></a> and <a href="https://github.com/bhaskarvk/docker"><code>docker</code></a> (the package that manages docker from R), you need to grab them from github.</p>
<p>The github page of <a href="https://github.com/bhaskarvk/docker"><code>docker</code></a> (the R package) explains how to install the python package <a href="https://docker-py.readthedocs.io/en/stable/"><code>docker</code></a>. Yes, you read that well: in order to use <a href="http://splash.readthedocs.io"><code>splash</code></a> (the scrapping python lib), <a href="https://github.com/hrbrmstr/%5Bsplashr"><code>splashr</code></a> uses:</p>
<ul>
<li><a href="https://github.com/bhaskarvk/docker"><code>docker</code></a> (the R package),
<ul>
<li>which uses <a href="https://docker-py.readthedocs.io/en/stable/"><code>docker</code></a> (the python lib installed in a virtualenv named <code>docker</code>),
<ul>
<li>which uses <a href="https://www.docker.com/"><code>docker</code></a> (the container engine).</li>
</ul></li>
</ul></li>
</ul>
<p>So proceed in steps:</p>
<ol style="list-style-type: decimal">
<li>Install <a href="https://www.docker.com/"><code>docker</code></a> (the engine)</li>
<li>Install <a href="https://docker-py.readthedocs.io/en/stable/"><code>docker</code></a> (the python lib) in a virtualenv like explained <a href="https://github.com/bhaskarvk/docker">here</a></li>
<li>Install the R packages</li>
</ol>
<pre><code>devtools::install_github(&quot;bhaskarvk/docker&quot;)
devtools::install_github(&quot;hrbrmstr/splashr&quot;)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Let RStudio know that you want python commands to be run in this virtualenv</li>
</ol>
<pre class="r"><code># Use the path where you installed the docker venv
reticulate::use_virtualenv(&quot;~/dev/virtualenvs/docker&quot;, required=T)</code></pre>
<p>The very first time we run <code>splashr</code>, it might be a bit slow: it will have to download the docker image (the template used to create container) that has <code>Splash</code> installed in it. The image is documented <a href="https://hub.docker.com/r/hrbrmstr/splashttpd/">here</a>.</p>
<pre class="r"><code>suppressMessages(library(splashr))
install_splash()</code></pre>
<pre><code>## Pulling from scrapinghub/splash</code></pre>
<pre><code>## Digest: sha256:08c9b401fb812c9bf6591773c88c73b0c535336b97dd1ac04f9dbb988b2a7f76</code></pre>
<pre><code>## Status: Image is up to date for scrapinghub/splash:3.0</code></pre>
<p>We can then use <code>splashr</code> to create a <code>splash</code> container and get the <code>html</code>, this time with javascript generated content in it. The <code>xml2</code> functions can still be used on the html returned by <code>splashr</code>.</p>
<p>I added a wait time of two seconds between <code>start_splash</code> and <code>render_html</code> because I kept getting errors looking like <code>render_html</code> was called before the container was fully operational.</p>
<pre class="r"><code>splash_container &lt;- splashr::start_splash()
Sys.sleep(2)
listing_html_js &lt;- splashr::render_html(url = listing_url)

count &lt;- listing_html_js %&gt;%
  html_node(&quot;#count-search&quot;) %&gt;%
  html_text()
print(paste(&quot;count value is:&quot;, count))</code></pre>
<pre><code>## [1] &quot;count value is: (32 results)&quot;</code></pre>
<p>The number is extracted with a little regular expression and the <code>stringr</code> package:</p>
<pre class="r"><code>offer_number &lt;- stringr::str_extract(count, &quot;[0-9]+&quot;) 
print(paste(&quot;offer_number value is:&quot;, offer_number))</code></pre>
<pre><code>## [1] &quot;offer_number value is: 32&quot;</code></pre>
<p>Don’t forget to stop and delete your container.</p>
<pre class="r"><code>stop_splash(splash_container)</code></pre>
<p>We now have the expected number of offers, which we can use to verify our final dataset (read <a href="https://xvrdm.github.io/2017/03/31/scrape-a-list-of-rental-offers-using-rvest-and-purrr/">previous post</a> to see how).</p>
</div>
</div>
